{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content:\n",
    "- Train text classifier on custom labels (market sematic)\n",
    "\n",
    "#### TODO:\n",
    "- filename_to_id for reuters and bloomberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path for importing from src dir\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "from sklearn import metrics\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import NyseSecuritiesDataset\n",
    "from src.datasets import NyseStocksDataset\n",
    "from src.datasets import NyseFundamentalsDataset\n",
    "import src.nlp_utils as nlp_utils\n",
    "import src.text_classification_utils as tc_utils\n",
    "\n",
    "HOME = \"..\"\n",
    "DATA_DIR = \"data\"\n",
    "REUTERS = os.path.join(HOME, DATA_DIR, \"preprocessed\", \"news_reuters.csv\")\n",
    "BLOOMBERG = os.path.join(HOME, DATA_DIR, \"preprocessed\", \"news_bloomberg.csv\")\n",
    "NEWS = os.path.join(HOME, DATA_DIR, \"preprocessed\", \"news.csv\")\n",
    "\n",
    "stocks_ds = NyseStocksDataset(file_path='../data/nyse/prices-split-adjusted.csv'); stocks_ds.load()\n",
    "securities_ds = NyseSecuritiesDataset(file_path='../data/nyse/securities.csv'); securities_ds.load()\n",
    "companies = securities_ds.get_all_company_names()  # List[Tuple[symbol, name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skiprows: 48000 -> 10-03-22, 47000 -> 10-02-22, 45400 -> 10-01-05\n",
    "NEWS_ARTICLE_START = '2010-03-22'\n",
    "news = tc_utils.load_news(REUTERS, start_date=NEWS_ARTICLE_START)\n",
    "\n",
    "occs_per_article = tc_utils.get_occs_per_article()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all articles with enough occurrences\n",
    "MIN_OCCURRENCES = 5  # for one company\n",
    "rel_article_tuples = tc_utils.get_relevant_articles(news, occs_per_article, securities_ds, min_occ=MIN_OCCURRENCES)\n",
    "# Remove those which are not available in the training dataset of stock prices\n",
    "rel_article_tuples = [x for x in rel_article_tuples if stocks_ds.is_company_available(x[0])]\n",
    "print(f'Selected {len(rel_article_tuples)} relevant article tuples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOOK_BACK = 30\n",
    "FORECAST = 0\n",
    "continuous_labels = np.array([get_label(*x, stocks_ds, look_back=LOOK_BACK, forecast=FORECAST)\n",
    "                              for x in tqdm(rel_article_tuples)])\n",
    "print(f'Generated labels for {len(rel_article_tuples)} articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = tc_utils.split_shuffled(rel_article_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From tutorial\n",
    "https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\n",
    "\n",
    "### Experiment 1:\n",
    "- Use 30 last days until open of the current day (for articles on weekends go back to friday)\n",
    "- Articles from NYSE start 2010-03-22 to Reuters end 2012-12-31 [not touched final test set will be 2013-01-01 to 2013-11-20 with 3901-2803=1098 articles]\n",
    "- Only use title and real body (with some exceptions)\n",
    "- Don't remove numbers, links, special characters from vectorizer\n",
    "- Label \"1\": 829 samples\n",
    "- Label \"-1\": 1017 samples\n",
    "- Label \"0\": 957 samples\n",
    "- Train: 2242 out of 2803 shuffled samples (Test: 561 samples)\n",
    "- LinearSVC warns: \"ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\"\n",
    "\n",
    "##### Resulting metrics:\n",
    "- $Accuray=0.5$\n",
    "- $MCC=0.25$\n",
    "- classification_report:\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "            -1.0       0.56      0.53      0.54       209\n",
    "             0.0       0.49      0.46      0.48       198\n",
    "             1.0       0.45      0.51      0.48       154\n",
    "\n",
    "       micro avg       0.50      0.50      0.50       561\n",
    "       macro avg       0.50      0.50      0.50       561\n",
    "    weighted avg       0.51      0.50      0.50       561"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- Use absolute price diff for calculating label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n",
    "clf = LinearSVC()\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])\n",
    "\n",
    "# train\n",
    "print(\"Training...\")\n",
    "pipe.fit(train_X, train_y)\n",
    "# test\n",
    "print(\"Testing...\")\n",
    "preds = pipe.predict(test_X)\n",
    "\n",
    "# # Print 10 best words for 2 classes\n",
    "# print(\"Top 10 features used to predict: \")\n",
    "# printNMostInformative(vectorizer, clf, 10)\n",
    "# # Get counts of each word\n",
    "# vect_pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer)])\n",
    "# print(\"Training #2...\")\n",
    "# transform = vect_pipe.fit_transform(train1, labelsTrain1)\n",
    "# vocab = vectorizer.get_feature_names()\n",
    "# for i in range(len(train1)):\n",
    "#     s = \"\"\n",
    "#     indexIntoVocab = transform.indices[transform.indptr[i]:transform.indptr[i+1]]\n",
    "#     numOccurences = transform.data[transform.indptr[i]:transform.indptr[i+1]]\n",
    "#     for idx, num in zip(indexIntoVocab, numOccurences):\n",
    "#         s += str((vocab[idx], num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"- Accuracy: {accuracy_score(test_y, preds):.2f}\")\n",
    "print(f\"- MCC: {matthews_corrcoef(test_y, preds):.2f}\")\n",
    "print(metrics.classification_report(test_y, preds).replace('\\n', '\\n    '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect completeness of NYSE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals_ds = NyseFundamentalsDataset(file_path='../data/nyse/fundamentals.csv');\n",
    "fund_data = fundamentals_ds.data()\n",
    "\n",
    "fund_symbols = set(fund_data['Ticker Symbol'].unique())\n",
    "securities_symbols = set(securities_ds.get_all_company_names()['Ticker symbol'].values)\n",
    "prices = pd.read_csv('../data/nyse/prices-split-adjusted.csv')\n",
    "prices_symbols = set(prices.symbol.unique())\n",
    "\n",
    "fund_companies_without_sec = fund_symbols - securities_symbols\n",
    "fund_companies_without_prices = fund_symbols - prices_symbols\n",
    "sec_comp_without_fund = securities_symbols - fund_symbols\n",
    "sec_comp_without_prices = securities_symbols - prices_symbols\n",
    "prices_comp_without_fund = prices_symbols - fund_symbols\n",
    "prices_comp_without_sec = prices_symbols - securities_symbols\n",
    "\n",
    "print(f'Fund companies: {len(fund_symbols)}, Sec companies: {len(securities_symbols)}, Price companies: {len(prices_symbols)}\\n')\n",
    "print('fund_companies_without_sec:', sorted(fund_companies_without_sec), '\\n')\n",
    "print('fund_companies_without_prices:', sorted(fund_companies_without_prices), '\\n')\n",
    "print('sec_comp_without_fund:', sorted(sec_comp_without_fund), '\\n')\n",
    "print('sec_comp_without_prices:', sorted(sec_comp_without_prices), '\\n')\n",
    "print('prices_comp_without_fund:', sorted(prices_comp_without_fund), '\\n')\n",
    "print('prices_comp_without_sec:', sorted(prices_comp_without_sec), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
